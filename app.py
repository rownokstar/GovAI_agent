import streamlit as st
from langchain_core.messages import AIMessage, HumanMessage
from langchain_community.document_loaders import PyPDFLoader, CSVLoader, Docx2txtLoader, UnstructuredExcelLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import FAISS
from langchain_openai import OpenAIEmbeddings
from langchain_groq import ChatGroq
from langchain_core.prompts import ChatPromptTemplate
from langchain.chains.combine_documents import create_stuff_documents_chain
from langchain.chains import create_retrieval_chain
import os
from fpdf import FPDF
from docx import Document as DocxDocument
import pandas as pd
import io

# --- ‡¶™‡ßá‡¶ú ‡¶ï‡¶®‡¶´‡¶ø‡¶ó‡¶æ‡¶∞‡ßá‡¶∂‡¶® ---
st.set_page_config(page_title="GovAI Pro 2.0", page_icon="ü§ñ", layout="wide")
st.title("ü§ñ GovAI Pro 2.0 - ‡¶Ü‡¶™‡¶®‡¶æ‡¶∞ ‡¶á‡¶®‡ßç‡¶ü‡¶æ‡¶∞‡ßá‡¶ï‡ßç‡¶ü‡¶ø‡¶≠ ‡¶°‡¶ï‡ßÅ‡¶Æ‡ßá‡¶®‡ßç‡¶ü ‡¶Ö‡ßç‡¶Ø‡¶æ‡¶∏‡¶ø‡¶∏‡ßç‡¶ü‡ßç‡¶Ø‡¶æ‡¶®‡ßç‡¶ü")

# --- ‡¶∏‡¶æ‡¶á‡¶°‡¶¨‡¶æ‡¶∞ ---
with st.sidebar:
    st.header("üõ†Ô∏è ‡¶ï‡¶®‡¶´‡¶ø‡¶ó‡¶æ‡¶∞‡ßá‡¶∂‡¶®")
    st.markdown("API Key-‡¶ó‡ßÅ‡¶≤‡ßã ‡¶è‡¶ñ‡¶® Streamlit Secrets ‡¶•‡ßá‡¶ï‡ßá ‡¶∏‡ßç‡¶¨‡¶Ø‡¶º‡¶Ç‡¶ï‡ßç‡¶∞‡¶ø‡¶Ø‡¶º‡¶≠‡¶æ‡¶¨‡ßá ‡¶≤‡ßã‡¶° ‡¶π‡¶ö‡ßç‡¶õ‡ßá‡•§")
    
    if st.button("üí¨ ‡¶®‡¶§‡ßÅ‡¶® ‡¶ö‡ßç‡¶Ø‡¶æ‡¶ü ‡¶∂‡ßÅ‡¶∞‡ßÅ ‡¶ï‡¶∞‡ßÅ‡¶®", use_container_width=True):
        st.session_state.clear()
        st.rerun()

    st.markdown("---")
    st.info("‡¶è‡¶á ‡¶Ö‡ßç‡¶Ø‡¶æ‡¶™‡¶ü‡¶ø ‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ, ‡¶á‡¶Ç‡¶∞‡ßá‡¶ú‡¶ø ‡¶è‡¶¨‡¶Ç ‡¶¨‡¶æ‡¶Ç‡¶≤‡¶ø‡¶∂ ‡¶≠‡¶æ‡¶∑‡¶æ‡ßü ‡¶ï‡¶æ‡¶ú ‡¶ï‡¶∞‡¶§‡ßá ‡¶™‡¶æ‡¶∞‡ßá‡•§")


# --- API ‡¶ï‡ßÄ ‡¶≤‡ßã‡¶° ‡¶ï‡¶∞‡¶æ ---
groq_api_key = st.secrets.get("GROQ_API_KEY")
openai_api_key = st.secrets.get("OPENAI_API_KEY")

if not groq_api_key or not openai_api_key:
    st.error("‡¶Ö‡¶®‡ßÅ‡¶ó‡ßç‡¶∞‡¶π ‡¶ï‡¶∞‡ßá Streamlit Cloud-‡¶è‡¶∞ Settings > Secrets ‡¶∏‡ßá‡¶ï‡¶∂‡¶®‡ßá ‡¶Ü‡¶™‡¶®‡¶æ‡¶∞ Groq ‡¶è‡¶¨‡¶Ç OpenAI API Key ‡¶Ø‡ßã‡¶ó ‡¶ï‡¶∞‡ßÅ‡¶®‡•§")
    st.stop()

# --- ‡¶´‡¶æ‡¶Ç‡¶∂‡¶®‡¶∏‡¶Æ‡ßÇ‡¶π ---

def get_vectorstore_from_file(uploaded_file):
    if "vector_store" in st.session_state and st.session_state.get("uploaded_file_name") == uploaded_file.name:
        return st.session_state.vector_store
    
    try:
        file_extension = os.path.splitext(uploaded_file.name)[1]
        temp_file_path = os.path.join("/tmp", uploaded_file.name)
        
        with open(temp_file_path, "wb") as f:
            f.write(uploaded_file.getbuffer())

        if file_extension == ".pdf":
            loader = PyPDFLoader(temp_file_path)
        elif file_extension == ".docx":
            loader = Docx2txtLoader(temp_file_path)
        elif file_extension == ".csv":
            loader = CSVLoader(temp_file_path)
        elif file_extension in [".xls", ".xlsx"]:
            loader = UnstructuredExcelLoader(temp_file_path, mode="elements")
        else:
            st.error("‡¶è‡¶á ‡¶´‡¶æ‡¶á‡¶≤ ‡¶´‡¶∞‡¶Æ‡ßç‡¶Ø‡¶æ‡¶ü‡¶ü‡¶ø ‡¶∏‡¶æ‡¶™‡ßã‡¶∞‡ßç‡¶ü ‡¶ï‡¶∞‡ßá ‡¶®‡¶æ‡•§")
            return None
        
        documents = loader.load()
        text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)
        document_chunks = text_splitter.split_documents(documents)
        
        embeddings = OpenAIEmbeddings(openai_api_key=openai_api_key)
        vector_store = FAISS.from_documents(document_chunks, embeddings)

        st.session_state.vector_store = vector_store
        st.session_state.uploaded_file_name = uploaded_file.name
        os.remove(temp_file_path)
        return vector_store
    except Exception as e:
        st.error(f"‡¶´‡¶æ‡¶á‡¶≤ ‡¶™‡ßç‡¶∞‡¶∏‡ßá‡¶∏‡¶ø‡¶Ç-‡¶è ‡¶∏‡¶Æ‡¶∏‡ßç‡¶Ø‡¶æ ‡¶π‡ßü‡ßá‡¶õ‡ßá: {e}")
        return None

def get_context_retriever_chain(vector_store):
    llm = ChatGroq(temperature=0.2, groq_api_key=groq_api_key, model_name="Llama3-70b-8192")
    
    retriever = vector_store.as_retriever()
    
    prompt = ChatPromptTemplate.from_messages([
      ("system", "Answer the user's questions based on the below context:\n\n{context}"),
      ("user", "{input}"),
    ])
    
    stuff_documents_chain = create_stuff_documents_chain(llm, prompt)
    return create_retrieval_chain(retriever, stuff_documents_chain)

def get_conversational_rag_chain(retriever_chain):
    llm = ChatGroq(temperature=0.2, groq_api_key=groq_api_key, model_name="Llama3-70b-8192")
    
    prompt = ChatPromptTemplate.from_messages([
      ("system", """You are a helpful and friendly AI assistant named GovAI Pro. Answer the user's questions based on the provided context and conversation history.

Language Rules:
- If the user asks in English, respond in English.
- If the user asks in Bengali (‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ), respond in clear Bengali.
- If the user asks in Banglish (e.g., "amar kisu document lagbe"), understand it as Bengali and respond in clear Bengali.

Formatting Rules:
- Use appropriate emojis to make the conversation engaging. üëç
- If you need to present structured data (like comparisons, lists of items, etc.), use Markdown tables.
- If you don't know the answer from the context, politely say so in the correct language.

Context: {context}"""),
      ("user", "{input}"),
    ])
    
    stuff_documents_chain = create_stuff_documents_chain(llm, prompt)
    return create_retrieval_chain(retriever_chain.retriever, stuff_documents_chain)

# --- ‡¶∞‡¶ø‡¶™‡ßã‡¶∞‡ßç‡¶ü ‡¶ú‡ßá‡¶®‡¶æ‡¶∞‡ßá‡¶ü ‡¶´‡¶æ‡¶Ç‡¶∂‡¶® ---
def generate_pdf_report(chat_history):
    pdf = FPDF()
    pdf.add_page()
    pdf.add_font('DejaVu', '', '/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf', uni=True)
    pdf.set_font('DejaVu', '', 12)
    
    pdf.cell(200, 10, txt="GovAI Pro - Chat Report", ln=True, align='C')
    
    for message in chat_history:
        role = "User" if isinstance(message, HumanMessage) else "Assistant"
        # Correctly handle potential encoding issues for the content
        content = message.content.encode('latin-1', 'replace').decode('latin-1')
        pdf.multi_cell(0, 10, f"{role}: {content}")
        pdf.ln(5)
        
    return pdf.output(dest='S').encode('latin-1')

def generate_docx_report(chat_history):
    document = DocxDocument()
    document.add_heading('GovAI Pro - Chat Report', 0)
    
    for message in chat_history:
        role = "User" if isinstance(message, HumanMessage) else "Assistant"
        document.add_paragraph(f"{role}: {message.content}")
        
    bio = io.BytesIO()
    document.save(bio)
    return bio.getvalue()

def generate_excel_report(chat_history):
    data = {"Role": [], "Message": []}
    for message in chat_history:
        role = "User" if isinstance(message, HumanMessage) else "Assistant"
        data["Role"].append(role)
        data["Message"].append(message.content)
        
    df = pd.DataFrame(data)
    bio = io.BytesIO()
    with pd.ExcelWriter(bio, engine='openpyxl') as writer:
        df.to_excel(writer, index=False, sheet_name='Chat History')
    return bio.getvalue()

# --- ‡¶∏‡ßá‡¶∂‡¶® ‡¶∏‡ßç‡¶ü‡ßá‡¶ü ‡¶∂‡ßÅ‡¶∞‡ßÅ ‡¶ï‡¶∞‡¶æ ---
if "chat_history" not in st.session_state:
    st.session_state.chat_history = [AIMessage(content="‡§®‡§Æ‡§∏‡•ç‡§§‡•á! ‡¶Ü‡¶Æ‡¶ø GovAI Pro‡•§ ‡¶Ü‡¶™‡¶®‡¶æ‡¶∞ ‡¶°‡¶ï‡ßÅ‡¶Æ‡ßá‡¶®‡ßç‡¶ü ‡¶Ü‡¶™‡¶≤‡ßã‡¶° ‡¶ï‡¶∞‡ßÅ‡¶® ‡¶è‡¶¨‡¶Ç ‡¶™‡ßç‡¶∞‡¶∂‡ßç‡¶® ‡¶ú‡¶ø‡¶ú‡ßç‡¶û‡¶æ‡¶∏‡¶æ ‡¶∂‡ßÅ‡¶∞‡ßÅ ‡¶ï‡¶∞‡ßÅ‡¶®‡•§")]

# --- ‡¶´‡¶æ‡¶á‡¶≤ ‡¶Ü‡¶™‡¶≤‡ßã‡¶° ‡¶è‡¶¨‡¶Ç ‡¶™‡ßç‡¶∞‡¶∏‡ßá‡¶∏‡¶ø‡¶Ç ---
uploaded_file = st.file_uploader(
    "üìÑ ‡¶Ü‡¶™‡¶®‡¶æ‡¶∞ ‡¶°‡¶ï‡ßÅ‡¶Æ‡ßá‡¶®‡ßç‡¶ü ‡¶Ü‡¶™‡¶≤‡ßã‡¶° ‡¶ï‡¶∞‡ßÅ‡¶® (PDF, DOCX, CSV, Excel)", 
    type=['pdf', 'docx', 'csv', 'xls', 'xlsx'],
    help="‡¶è‡¶ñ‡¶æ‡¶®‡ßá ‡¶´‡¶æ‡¶á‡¶≤ ‡¶Ü‡¶™‡¶≤‡ßã‡¶° ‡¶ï‡¶∞‡¶æ‡¶∞ ‡¶™‡¶∞ ‡¶Ü‡¶™‡¶®‡¶ø ‡¶™‡ßç‡¶∞‡¶∂‡ßç‡¶® ‡¶ï‡¶∞‡¶§‡ßá ‡¶™‡¶æ‡¶∞‡¶¨‡ßá‡¶®‡•§"
)

if not uploaded_file:
    st.info("‡¶è‡¶ï‡¶ü‡¶ø ‡¶°‡¶ï‡ßÅ‡¶Æ‡ßá‡¶®‡ßç‡¶ü ‡¶Ü‡¶™‡¶≤‡ßã‡¶° ‡¶ï‡¶∞‡ßá ‡¶∂‡ßÅ‡¶∞‡ßÅ ‡¶ï‡¶∞‡ßÅ‡¶®‡•§")
else:
    with st.spinner("‡¶Ü‡¶™‡¶®‡¶æ‡¶∞ ‡¶°‡¶ï‡ßÅ‡¶Æ‡ßá‡¶®‡ßç‡¶ü ‡¶™‡ßç‡¶∞‡¶∏‡ßá‡¶∏ ‡¶ï‡¶∞‡¶æ ‡¶π‡¶ö‡ßç‡¶õ‡ßá... ‚è≥"):
        vector_store = get_vectorstore_from_file(uploaded_file)
        if vector_store is not None:
            retriever_chain = get_context_retriever_chain(vector_store)

            # --- ‡¶ö‡ßç‡¶Ø‡¶æ‡¶ü ‡¶π‡¶ø‡¶∏‡ßç‡¶ü‡ßç‡¶∞‡¶ø ‡¶°‡¶ø‡¶∏‡¶™‡ßç‡¶≤‡ßá ---
            for message in st.session_state.chat_history:
                if isinstance(message, AIMessage):
                    with st.chat_message("AI", avatar="ü§ñ"):
                        st.write(message.content)
                elif isinstance(message, HumanMessage):
                    with st.chat_message("Human", avatar="üë§"):
                        st.write(message.content)

            # --- ‡¶á‡¶â‡¶ú‡¶æ‡¶∞ ‡¶á‡¶®‡¶™‡ßÅ‡¶ü ---
            user_query = st.chat_input("‡¶Ü‡¶™‡¶®‡¶æ‡¶∞ ‡¶™‡ßç‡¶∞‡¶∂‡ßç‡¶® ‡¶è‡¶ñ‡¶æ‡¶®‡ßá ‡¶≤‡¶ø‡¶ñ‡ßÅ‡¶®...")
            if user_query:
                st.session_state.chat_history.append(HumanMessage(content=user_query))
                
                with st.chat_message("Human", avatar="üë§"):
                    st.write(user_query)

                with st.chat_message("AI", avatar="ü§ñ"):
                    # streaming response
                    def stream_response():
                        chain = get_conversational_rag_chain(retriever_chain)
                        response = chain.invoke({
                            "input": user_query,
                            "context": st.session_state.chat_history
                        })
                        return response['answer']

                    full_response = st.write_stream(stream_response)
                    st.session_state.chat_history.append(AIMessage(content=full_response))

                    # --- ‡¶°‡¶æ‡¶â‡¶®‡¶≤‡ßã‡¶° ‡¶¨‡¶æ‡¶ü‡¶® ---
                    st.markdown("---")
                    st.write("‡¶è‡¶á ‡¶Ü‡¶≤‡ßã‡¶ö‡¶®‡¶æ‡¶ü‡¶ø ‡¶°‡¶æ‡¶â‡¶®‡¶≤‡ßã‡¶° ‡¶ï‡¶∞‡ßÅ‡¶®:")
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.download_button(
                            label="üìÑ PDF ‡¶π‡¶ø‡¶∏‡¶æ‡¶¨‡ßá",
                            data=generate_pdf_report(st.session_state.chat_history),
                            file_name="chat_report.pdf",
                            mime="application/pdf",
                            use_container_width=True
                        )
                    with col2:
                        st.download_button(
                            label="üìë DOCX ‡¶π‡¶ø‡¶∏‡¶æ‡¶¨‡ßá",
                            data=generate_docx_report(st.session_state.chat_history),
                            file_name="chat_report.docx",
                            mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document",
                            use_container_width=True
                        )
                    with col3:
                        st.download_button(
                            label="üìä Excel ‡¶π‡¶ø‡¶∏‡¶æ‡¶¨‡ßá",
                            data=generate_excel_report(st.session_state.chat_history),
                            file_name="chat_report.xlsx",
                            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                            use_container_width=True
                        )
