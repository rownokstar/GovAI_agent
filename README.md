
# ğŸ¤– GovAI Agent â€“ Local LLM Government Assistant

[![Python](https://img.shields.io/badge/Python-3776AB?style=for-the-badge&logo=python&logoColor=white)](https://python.org)
[![Streamlit](https://img.shields.io/badge/Streamlit-FF4B4B?style=for-the-badge&logo=streamlit&logoColor=white)](https://streamlit.io)
[![HuggingFace](https://img.shields.io/badge/HuggingFace-%23FFD21E.svg?style=for-the-badge&logo=huggingface&logoColor=000)](https://huggingface.co)
[![License](https://img.shields.io/badge/License-MIT-green?style=for-the-badge)](LICENSE)
[![Open Source](https://img.shields.io/badge/Open%20Source-%E2%9D%A4-red?style=for-the-badge)](https://opensource.org)

**GovAI Agent** is an intelligent, privacy-focused AI assistant designed to answer questions about government schemes, acts, and citizen services. It leverages the power of local Large Language Models (LLMs) like Llama 3, combined with Retrieval-Augmented Generation (RAG) using FAISS, to provide accurate and contextual answers directly from your uploaded government-related datasets. No external API keys are required â€“ everything runs locally on your machine.

> ğŸš€ **Upload Government Data** â†’ ğŸ¤– **AI Parses & Understands** â†’ ğŸ’¬ **Get Instant, Contextual Answers**



## ğŸŒŸ **Why GovAI Agent?**

<div align="center">

| Feature | Description |
|---------|-------------|
| ğŸ›¡ï¸ **Privacy First** | All data processing and AI inference happen locally. Your sensitive government data never leaves your computer. |
| ğŸ§  **Smart Local AI** | Utilizes powerful open-source LLMs like Llama 3 for deep understanding without relying on external services. |
| ğŸ” **RAG-Powered Accuracy** | Employs Retrieval-Augmented Generation to find relevant information in your documents before generating answers. |
| ğŸ’¬ **Natural Interaction** | Ask questions in plain English about complex government documents and get clear, concise responses. |
| âš¡ **Dynamic Processing** | Automatically indexes and processes your uploaded CSV or text datasets for immediate querying. |

</div>



## ğŸ¯ **Key Features**

### ğŸ“‚ **Intelligent Dataset Handling**
- **Universal Upload**: Supports CSV and (planned) text document uploads.
- **Auto-Indexing**: Automatically processes and indexes data using Sentence Transformers and FAISS for fast retrieval.
- **Real-time RAG**: Context from your data is injected into the LLM for accurate answers.

### ğŸ’¬ **Advanced AI Assistant**
- **Context-Aware Queries**: "What are the eligibility criteria for PMAY listed in this document?"
- **Summarization**: "Summarize the key points of the National Education Policy 2020."
- **Data Extraction**: "List all schemes related to agriculture and their funding agencies."
- **Smart Reasoning**: AI shows its step-by-step thinking process.

### ğŸ› ï¸ **Technical Excellence**
- **RAG Architecture**: Combines retrieval (FAISS) with generation (Llama 3) for factual responses.
- **Local LLM Execution**: Runs Llama 3 (or similar) directly on your hardware using Hugging Face `transformers`.
- **Scalable Design**: Efficiently handles datasets of significant size.
- **Error Resilience**: Built-in handling for data and model loading issues.



## ğŸ¯ **How It Works**


```mermaid
graph TD
    A[User Uploads Dataset] --> B[Auto Data Processing]
    B --> C[Text Embedding (Sentence Transformers)]
    C --> D[FAISS Vector Index Creation]
    D --> E[RAG Query Loop]
    E --> F[User Question]
    F --> G[Query Embedding]
    G --> H[FAISS Similarity Search]
    H --> I[Retrieve Relevant Context]
    I --> J[Llama 3 Prompt Engineering]
    J --> K[Local LLM Inference (Hugging Face)]
    K --> L[Generate Contextual Answer]
    L --> M[Display Answer + Thinking Steps]
## ğŸ› ï¸ **Technology Stack**

<div align="center">

| Component | Technology | Purpose |
|-----------|------------|---------|
| **Frontend** | ğŸŒ Streamlit | Interactive web UI |
| **Backend** | ğŸ Python | Core logic & orchestration |
| **AI Engine** | ğŸ¤– Hugging Face Transformers | Load & run Llama 3 |
| **Embeddings** | ğŸ§  Sentence Transformers | Create vector representations |
| **Search** | ğŸ” FAISS | Fast similarity search on local data |
| **Data Processing** | ğŸ“¦ Pandas/NumPy | Handle & manipulate datasets |

</div>

---

## ğŸš€ **Quick Start**

### ğŸ”§ **Local Installation & Running**

1.  **Clone the Repository**
    ```bash
    git clone https://github.com/rownokstar/GovAI_agent.git
    cd GovAI_agent
    ```

2.  **Set Up Python Environment** (Recommended)
    ```bash
    python -m venv venv
    source venv/bin/activate # On Windows: venv\Scripts\activate
    ```

3.  **Install Dependencies**
    ```bash
    pip install -r requirements.txt
    ```

4.  **(Crucial) Obtain Hugging Face Access & Token**
    *   Create a Hugging Face account: [https://huggingface.co/](https://huggingface.co/)
    *   Request access to the Llama 3 model (e.g., `meta-llama/Meta-Llama-3-8B-Instruct`) on the Hugging Face website.
    *   Generate an Access Token: Go to your profile -> Settings -> Access Tokens -> New token.
    *   Log in via CLI:
        ```bash
        huggingface-cli login
        ```
        Paste your token when prompted. This allows the app to download the Llama 3 model.

5.  **Run the Application**
    ```bash
    streamlit run app.py
    ```
    Your default web browser should open automatically. If not, navigate to the URL provided in the terminal (usually `http://localhost:8501`).

---

## ğŸ“ **Project Structure**

```
GovAI_agent/
â”œâ”€â”€ app.py                 # Main Streamlit application
â”œâ”€â”€ requirements.txt       # Python dependencies
â”œâ”€â”€ README.md             # This file
â”œâ”€â”€ LICENSE               # MIT License
â””â”€â”€ .gitignore            # Specifies files/dirs to ignore in Git
```

---

## ğŸ¯ **Smart Features Breakdown**

### ğŸ§  **Local LLM Inference**
- Runs powerful models like Llama 3 directly on your machine.
- Uses Hugging Face `transformers` and `pipeline` for easy loading and generation.
- Includes optional 4-bit quantization (`bitsandbytes`) to reduce memory requirements.

### ğŸ” **RAG Pipeline**
- **Data Ingestion**: Uploaded CSV data is converted to text snippets.
- **Embedding**: Snippets are embedded using `all-MiniLM-L6-v2`.
- **Indexing**: Embeddings are stored in a FAISS index for fast search.
- **Retrieval**: User queries are embedded and matched against the index.
- **Generation**: Retrieved context is formatted and sent to the Llama 3 model.

### ğŸ’¬ **Interactive & Transparent AI**
- **Thinking Process**: The app shows the AI's reasoning steps.
- **Natural Language**: Get answers in clear, understandable language.
- **Streaming Output**: Responses appear gradually for a better user experience.

---

## ğŸ§ª **Try These Examples (After Uploading Data)**

- "What are the key features of the Ayushman Bharat scheme?"
- "Find all grants available for startups in the uploaded document."
- "Summarize the section on digital infrastructure."
- "List the ministries mentioned and their respective schemes."
- "What are the application deadlines for rural development funds?"

---

## ğŸ¨ **User Interface Highlights**

### ğŸ“ **Smart Sidebar**
- **Dataset Upload**: Simple drag-and-drop for CSV files.
- **Processing Status**: Real-time feedback on data loading and indexing.
- **Dataset Preview**: Quick glance at the structure of your uploaded data.

### ğŸ’¬ **Chat Interface**
- **Natural Conversation**: Type your questions like you would ask a human expert.
- **Rich Responses**: Answers combined with the AI's reasoning steps.
- **History Tracking**: See your previous questions and the AI's responses.

---

## ğŸš€ **Advanced Capabilities**

### ğŸ”§ **Configurable LLM**
- Easily switch between different Hugging Face models (e.g., Llama 3 variants, Mistral) by modifying the `model_name` in `app.py`.

### âš¡ **Performance Optimizations**
- **Quantization**: 4-bit quantization significantly lowers VRAM usage for Llama 3.
- **Caching**: `@st.cache_resource` ensures the LLM is loaded only once per session.
- **Device Mapping**: Automatically utilizes GPU (if available) for faster inference.

---

## ğŸ“¸ **Screenshots** (Conceptual)

<div align="center">

### ğŸ“¤ **Upload & Process Government Data**
![Dataset Upload](https://placehold.co/600x300/4CAF50/white?text=Upload+Gov+Dataset)

### ğŸ’¬ **Ask Questions, Get AI-Powered Answers**
![Chat Interface](https://placehold.co/600x300/2196F3/white?text=AI+Chat+Interface)

### ğŸ§  **See the AI's Reasoning Process**
![Thinking Steps](https://placehold.co/600x300/FF9800/white?text=AI+Thinking+Process)

</div>

---

## ğŸ“‹ **Requirements**

Ensure you have these installed:
- **Python 3.8+**
- **Git** (for cloning)
- **pip** (Python package installer)
- **(Recommended) CUDA-compatible GPU** for faster Llama 3 inference (CPU will work but be slow).

Key libraries installed via `requirements.txt`:
```txt
streamlit>=1.29.0
pandas>=1.5.0
numpy>=1.24.0
faiss-cpu>=1.7.0
sentence-transformers>=2.2.0
transformers>=4.30.0
torch>=2.0.0
accelerate # For running large models
bitsandbytes # For 4-bit quantization (optional but recommended)
```

---

## ğŸ¤ **Contributing**

We welcome contributions! ğŸ‰

1. Fork the repository.
2. Create your feature branch (`git checkout -b feature/AmazingFeature`).
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`).
4. Push to the branch (`git push origin feature/AmazingFeature`).
5. Open a Pull Request.

### ğŸ¯ **Areas for Contribution**
- ğŸ“„ Support for PDF, TXT document uploads and parsing.
- ğŸŒ Multi-language support for queries and documents.
- ğŸ¨ UI/UX enhancements and custom themes.
- ğŸ“š Documentation improvements and examples.
- âš™ï¸ Adding more configuration options for the LLM and RAG pipeline.

---

## ğŸ“œ **License**

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

```
MIT License

Copyright (c) 2024 DM Shahriar Hossain

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction...
```

---

## ğŸŒŸ **Show Your Support**

If you find this project useful:

- â­ **Star this repository**
- ğŸ”„ **Share with colleagues**
- ğŸ› **Report issues**
- ğŸ’¡ **Suggest features**
- ğŸ¤ **Contribute code**

---

## ğŸ™Œ **Credits & Acknowledgements**

### ğŸ‘¨â€ğŸ’» **Development**
- **Lead Developer**: [DM Shahriar Hossain](https://github.com/rownokstar)
- **AI Specialist**: Hugging Face Transformers Community
- **UI Framework**: Streamlit

### ğŸ› ï¸ **Built With**
- **Python**: Core programming language.
- **Streamlit**: For rapid web application development.
- **FAISS**: For efficient vector similarity search.
- **Sentence Transformers**: For creating local embeddings.
- **Hugging Face Transformers**: For loading and running Llama 3.

### ğŸ¨ **Inspiration**
- Making government information more accessible through AI.
- Privacy-preserving local data processing.
- Leveraging open-source AI for public good.

---

## ğŸš€ **Ready to Empower Citizens?**

<div align="center">

[![GitHub](https://img.shields.io/badge/GitHub-100000?style=for-the-badge&logo=github&logoColor=white)](https://github.com/rownokstar/GovAI_agent)
[![License](https://img.shields.io/badge/License-MIT-green?style=for-the-badge)](LICENSE)

### ğŸ’¡ **Unlock the Knowledge in Government Documents Today!**

</div>

---

<details>
<summary>ğŸ” <b>Technical Details</b></summary>

### ğŸ§  **AI Architecture**
- **Default LLM**: `meta-llama/Meta-Llama-3-8B-Instruct` (configurable)
- **Embedding Model**: `all-MiniLM-L6-v2`
- **Search Engine**: FAISS FlatL2 Index
- **Processing Pipeline**: Dynamic RAG with local LLM

### âš¡ **Performance Considerations**
- **Model Loading**: First run will download the Llama 3 model (2-5 mins depending on internet).
- **Inference Speed**: Depends heavily on hardware. GPU (especially with quantization) is *much* faster than CPU.
- **Memory Usage**: Llama 3 8B quantized (~6-8 GB RAM/VRAM), Full precision (~16+ GB).
- **Scalability**: FAISS handles large local datasets efficiently.

### ğŸ›¡ï¸ **Security & Privacy**
- **Local Execution**: No data uploaded to external servers.
- **Token Storage**: Hugging Face token stored locally via `huggingface-cli login`.
- **Data Handling**: Uploaded files are processed in memory and not persisted.

</details>

---

<details>
<summary>ğŸ“¦ <b>Deployment Options</b></summary>

### â˜ï¸ **Cloud Deployment**
- **Challenges**: Running Llama 3 in the cloud requires significant resources (CPU/RAM or GPU).
- **Platforms**: Possible on platforms like RunPod, Vast.ai, or dedicated servers, but not typical free tiers.
- **Consideration**: API-based LLMs (like OpenAI) are easier for cloud deployment but compromise privacy.

### ğŸ–¥ï¸ **Local Deployment**
- **Windows/Mac/Linux**: Fully supported.
- **Docker**: Can be containerized (requires careful handling of model caching).
- **Virtual Environment**: Strongly recommended for dependency isolation.
- **Production Ready**: Suitable for local, secure, expert use.

</details>

---

<div align="center">

### ğŸ¤– **GovAI Agent - Bridging Citizens and Information**

[![Star](https://img.shields.io/github/stars/rownokstar/GovAI_agent?style=social)](https://github.com/rownokstar/GovAI_agent)
[![Fork](https://img.shields.io/github/forks/rownokstar/GovAI_agent?style=social)](https://github.com/rownokstar/GovAI_agent)
[![Issues](https://img.shields.io/github/issues/rownokstar/GovAI_agent?style=social)](https://github.com/rownokstar/GovAI_agent/issues)

</div>
```
